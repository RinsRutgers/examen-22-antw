{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 06:50:13.999 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "count = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "    \n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humor komt 31.414510476474533 % voor in de dataset, blind guess accuracy for this class: 7.853627619118633\n",
      "reuters komt 31.21318320781448 % voor in de dataset, blind guess accuracy for this class: 7.80329580195362\n",
      "wiki komt 31.175900380284844 % voor in de dataset, blind guess accuracy for this class: 7.793975095071211\n",
      "proverbs komt 6.196405935426143 % voor in de dataset, blind guess accuracy for this class: 1.5491014838565358\n"
     ]
    }
   ],
   "source": [
    "count = {\"humor\": 0, \"reuters\": 0, \"wiki\": 0, \"proverbs\": 0}\n",
    "total = len(traindataset)\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][1])\n",
    "    count[x] = count[x] + 1\n",
    "\n",
    "for style in d:\n",
    "    print(f'{style} komt {((count[style] / total ) * 100 )} % voor in de dataset, blind guess accuracy for this class: {((count[style] / total ) * 100 )*.25}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proverbs komt erg weining voor, daarom heeft het model weinig om daar van te leren. De nuance mist dan gok ik en je model wordt biased. \n",
    "\n",
    "ik dacht dat je de rest van de dataset kon trimmen tot een gelijwaardige verdeling, maar dit kan niet zo makkelijk zoals ik dacht omdat je inderdaad nog shuffled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        d = {\"humor\":0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "        return d[label]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1347]], dtype=torch.int32), tensor([2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "preprocessor([(x, y)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]),\n",
       " tensor([0, 0, 1, 1, 0, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 0, 1, 0, 0, 1,\n",
       "         0, 1, 0, 2, 2, 1, 2, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "import torch\n",
    "# TODO ~ 2 lines of code\n",
    "\n",
    "metrics = [metrics.Accuracy(), metrics.F1Score()]\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is een handige metric als je data goed evenredig versprijd is. Dat is hiet niet het geval. Voor ongebalanceerde datasets wordt F1score aangeraden. Bron: https://towardsdatascience.com/the-f1-score-bec2bbc38aa6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPmodel(\n",
      "  (emb): Embedding(19308, 128)\n",
      "  (rnn): GRU(128, 128, num_layers=3, batch_first=True, dropout=0.1)\n",
      "  (linear): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "log_dir = settings.log_dir\n",
    "# TODO between 2 and 8 lines of code, depending on your setup\n",
    "# Assuming you load your model in one line of code from src.models.rnn\n",
    "from src.models import rnn\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"input_size\": 32,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "model = rnn.NLPmodel(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419.09375 batches in traindataset\n",
      "16.76375 epochs\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(traindataset) / 32} batches in traindataset\")\n",
    "print(f\"{(len(traindataset) / 32)/25} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opmerking\n",
    "\n",
    "Hoi Raoul, bij bovenstaande vraag vraag ik mij af of de term epochs wel helemaal juist is, ik lees overal op het internet dat een epoch betekend dat je een keer door de hele dataset gaat. Maar als ik naar de vraag kijk lijkt dat niet helemaal op te gaan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.training import train_model\n",
    "\n",
    "# model = train_model.trainloop(\n",
    "#     epochs=64,\n",
    "#     model=model,\n",
    "#     metrics=metrics,\n",
    "#     optimizer=torch.optim.Adam,\n",
    "#     learning_rate=1e-3,\n",
    "#     loss_fn=loss_fn,\n",
    "#     train_dataloader=trainstreamer,\n",
    "#     test_dataloader=teststreamer,\n",
    "#     log_dir=\"../model/basis\",\n",
    "#     train_steps=25,\n",
    "#     eval_steps=25,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src = \"../figures/Screenshot 2022-07-21 at 16.01.07.png\">\n",
    "\n",
    "## Antwoord\n",
    "Je ziet dat het model leert en de loss op de train data flink minder wordt, dit zie je ook terug op de accuracy. Alleen de accuracy op de test data stagneert rond de 0.3, wat overeenkomt met de F1 score, wat aangeeft dat de F1 score hier dus echt een betere metric is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 15.0, 'Predicted'), Text(33.0, 0.5, 'Target')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(100):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder.\n",
    "Interpret this. \n",
    "\n",
    "<img src = \"../figures/matrix_2.png\">\n",
    "\n",
    "- What is going on?\n",
    "    \n",
    "- What is a good metric here?\n",
    "    \n",
    "- how is your answer to Q1 relevant here?\n",
    "    \n",
    "- Is there something you could do to fix/improve things, after you see these results?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als je de resultaten in losse klasses bekijkt wordt dijdelijk dat het model niet goed scoort bij klasse 3, in bijna 30 proces van de gevallen voorspelt het een andere klasse, vooral 0 en 2. Dit terwijl de andere klasse wel goed scoren. Niet geheel onlogisch want het model heeft in 6% van de tijd maar voorbeelden gezien van klasse 3. \n",
    "\n",
    "Accuracy is hier dus geen goede score omdat de dataset zo onevenredig verdeeld is. Gebruik maken van F1 score is al een goede eerste zet omdat je dan gebruik maakt van de precision en recall van alle classe in een metric. \n",
    "\n",
    "Je kunt als tweede oplossing resamplen, zodat de dataset gebalanceerder is. En dit kan op drie manieren: \n",
    "-   undersamping (van klasse 0-2 afhalen) niet handig denk ik want dan verlies je echt mega veel informatie. \n",
    "-   oversampling (delen van klasse 3 dupliceren), ook onhandig denk ik ivm overfitten. \n",
    "-   creeeren van nieuwe synthetic data. Waarbij ik niet denk dat je de laatste kunt gebruiken bij NLP. Althans, nee.. lijkt me onmogelijk. \n",
    "\n",
    "En je kunt natuurlijk het model aanpassen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 06:50:17.106239: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-08-12 06:50:18.862 | INFO     | src.data.data_tools:dir_add_timestamp:67 - Logging to ../tune/20220812-0650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     56   128  256  512\n",
      "0.1  NaN  NaN  NaN  NaN\n",
      "0.2  NaN  NaN  NaN  NaN\n",
      "0.3  NaN  NaN  NaN  NaN\n",
      "0.4  NaN  NaN  NaN  NaN\n",
      "NLPmodel(\n",
      "  (emb): Embedding(19308, 56)\n",
      "  (rnn): GRU(56, 56, num_layers=3, batch_first=True, dropout=0.1)\n",
      "  (linear): Linear(in_features=56, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 14.38it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.42it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.32it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.21it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.99it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.05it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.66it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.37it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.85it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.34it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.85it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.09it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.81it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.65it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.92it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.78it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.40it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 31.37it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30.66it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.11it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.73it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.53it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.35it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.78it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.10it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30.94it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.25it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.46it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.30it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.24it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.82it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.57it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.62it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.33it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.73it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.59it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.38it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.97it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.49it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.25it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.17it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.57it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.44it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.71it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.90it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.88it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.73it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.17it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.25it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.59it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.55it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.76it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.74it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.51it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.41it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.29it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.17it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.34it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.43it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.99it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.03it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.66it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.76it/s]\n",
      "100%|██████████| 64/64 [01:25<00:00,  1.34s/it]\n",
      "2022-08-12 06:51:44.364 | INFO     | src.data.data_tools:dir_add_timestamp:67 - Logging to ../tune/20220812-0651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        56   128  256  512\n",
      "0.1  0.8167  NaN  NaN  NaN\n",
      "0.2     NaN  NaN  NaN  NaN\n",
      "0.3     NaN  NaN  NaN  NaN\n",
      "0.4     NaN  NaN  NaN  NaN\n",
      "NLPmodel(\n",
      "  (emb): Embedding(19308, 56)\n",
      "  (rnn): GRU(56, 56, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (linear): Linear(in_features=56, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 12.64it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.44it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.51it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.77it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.35it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.52it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.82it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.98it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.14it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.35it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.02it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.07it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.75it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.51it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.69it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.42it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.18it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.65it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.71it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.57it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.79it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.48it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30.20it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.87it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.28it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.18it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 32.26it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.47it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.06it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.58it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 31.63it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 31.14it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.76it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.93it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.52it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.68it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.11it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.58it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.26it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.64it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.04it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.11it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.36it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.89it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.10it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.26it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.48it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.20it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.89it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 31.83it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.79it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.18it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.65it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.54it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.75it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.67it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.35it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.58it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.03it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30.11it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.50it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.28it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.23it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.33it/s]\n",
      "100%|██████████| 64/64 [01:24<00:00,  1.32s/it]\n",
      "2022-08-12 06:53:08.706 | INFO     | src.data.data_tools:dir_add_timestamp:67 - Logging to ../tune/20220812-0653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        56   128  256  512\n",
      "0.1  0.8167  NaN  NaN  NaN\n",
      "0.2  0.7824  NaN  NaN  NaN\n",
      "0.3     NaN  NaN  NaN  NaN\n",
      "0.4     NaN  NaN  NaN  NaN\n",
      "NLPmodel(\n",
      "  (emb): Embedding(19308, 56)\n",
      "  (rnn): GRU(56, 56, num_layers=3, batch_first=True, dropout=0.3)\n",
      "  (linear): Linear(in_features=56, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 14.10it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.08it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.87it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.55it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.38it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.48it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.20it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.43it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.69it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.52it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.38it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.29it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.27it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30.40it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.09it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.37it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.49it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.78it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.44it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.25it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.20it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.20it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.41it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.86it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30.61it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.29it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.04it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.82it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.48it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.68it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.47it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.29it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.67it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.59it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.89it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.89it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.75it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.73it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.51it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.49it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.40it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.16it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.00it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.02it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.19it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.20it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.60it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.30it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.36it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.32it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.36it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.59it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.95it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.79it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.72it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.05it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.45it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30.13it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.13it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.46it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.98it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.17it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.15it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.16it/s]\n",
      "100%|██████████| 64/64 [01:25<00:00,  1.33s/it]\n",
      "2022-08-12 06:54:33.740 | INFO     | src.data.data_tools:dir_add_timestamp:67 - Logging to ../tune/20220812-0654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        56   128  256  512\n",
      "0.1  0.8167  NaN  NaN  NaN\n",
      "0.2  0.7824  NaN  NaN  NaN\n",
      "0.3  0.7974  NaN  NaN  NaN\n",
      "0.4     NaN  NaN  NaN  NaN\n",
      "NLPmodel(\n",
      "  (emb): Embedding(19308, 56)\n",
      "  (rnn): GRU(56, 56, num_layers=3, batch_first=True, dropout=0.4)\n",
      "  (linear): Linear(in_features=56, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 13.14it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.51it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.15it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.72it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.59it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.80it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.44it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.06it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.07it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.83it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.27it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.13it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.09it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30.31it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.18it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.10it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.57it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.90it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 31.86it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.54it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.66it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.21it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.46it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.99it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.18it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.64it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.39it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.88it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.65it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.54it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.61it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.26it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.50it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.87it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.21it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.27it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.09it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.50it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.08it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.22it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.21it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.87it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.71it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.87it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.63it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.27it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.99it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.27it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.20it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 31.18it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.82it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.79it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.07it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.16it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.17it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30.74it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.88it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.85it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.41it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30.29it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.70it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.21it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 29.94it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.85it/s]\n",
      "100%|██████████| 64/64 [01:24<00:00,  1.33s/it]\n",
      "2022-08-12 06:55:58.708 | INFO     | src.data.data_tools:dir_add_timestamp:67 - Logging to ../tune/20220812-0655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        56   128  256  512\n",
      "0.1  0.8167  NaN  NaN  NaN\n",
      "0.2  0.7824  NaN  NaN  NaN\n",
      "0.3  0.7974  NaN  NaN  NaN\n",
      "0.4  0.7982  NaN  NaN  NaN\n",
      "NLPmodel(\n",
      "  (emb): Embedding(19308, 128)\n",
      "  (rnn): GRU(128, 128, num_layers=3, batch_first=True, dropout=0.1)\n",
      "  (linear): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00, 11.75it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.13it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.52it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.07it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.93it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.36it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.73it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.40it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.36it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.51it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.62it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.26it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.72it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.99it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.11it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.38it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.59it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.78it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.47it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.36it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.79it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.62it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.42it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.37it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.21it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.58it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.35it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.95it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.41it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.34it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.98it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.86it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.25it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.84it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.05it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.23it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.71it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.81it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.44it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.18it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.99it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.26it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.45it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.32it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.32it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.77it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.12it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.89it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.88it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.31it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.06it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.61it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.99it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.34it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.28it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.27it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.06it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.83it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.85it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.88it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.30it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.48it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.84it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.20it/s]\n",
      "100%|██████████| 64/64 [02:00<00:00,  1.89s/it]\n",
      "2022-08-12 06:57:59.496 | INFO     | src.data.data_tools:dir_add_timestamp:67 - Logging to ../tune/20220812-0657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        56      128  256  512\n",
      "0.1  0.8167  0.8585  NaN  NaN\n",
      "0.2  0.7824     NaN  NaN  NaN\n",
      "0.3  0.7974     NaN  NaN  NaN\n",
      "0.4  0.7982     NaN  NaN  NaN\n",
      "NLPmodel(\n",
      "  (emb): Embedding(19308, 128)\n",
      "  (rnn): GRU(128, 128, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (linear): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00, 11.24it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.75it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.97it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.08it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.21it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.94it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.95it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.85it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.63it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.47it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.53it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.90it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.06it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.46it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.98it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.94it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.53it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.76it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.11it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.73it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.01it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.70it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.19it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.68it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.74it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.23it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.64it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.53it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.11it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.18it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.85it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.89it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.12it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.37it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.10it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.53it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.07it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.76it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.67it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.32it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.90it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.91it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.81it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.78it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.62it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.65it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.40it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.35it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.38it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.41it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.96it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.28it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.48it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.22it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.20it/s]\n",
      " 36%|███▌      | 9/25 [00:00<00:01, 12.82it/s]]\n",
      " 86%|████████▌ | 55/64 [01:46<00:17,  1.94s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb Cell 41\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=19'>20</a>\u001b[0m model \u001b[39m=\u001b[39m rnn\u001b[39m.\u001b[39mNLPmodel(config)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=22'>23</a>\u001b[0m model \u001b[39m=\u001b[39m train_model\u001b[39m.\u001b[39;49mtrainloop(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=23'>24</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=24'>25</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=25'>26</a>\u001b[0m     metrics\u001b[39m=\u001b[39;49mmetrics,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=26'>27</a>\u001b[0m     optimizer\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=27'>28</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=28'>29</a>\u001b[0m     loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=29'>30</a>\u001b[0m     train_dataloader\u001b[39m=\u001b[39;49mtrainstreamer,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=30'>31</a>\u001b[0m     test_dataloader\u001b[39m=\u001b[39;49mteststreamer,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=31'>32</a>\u001b[0m     log_dir\u001b[39m=\u001b[39;49mlog_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=32'>33</a>\u001b[0m     train_steps\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=33'>34</a>\u001b[0m     eval_steps\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=34'>35</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=35'>36</a>\u001b[0m result\u001b[39m.\u001b[39mat[x,i] \u001b[39m=\u001b[39m  model[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d6173746572536572766572227d/home/rinsrutgers/examen-22-antw/notebooks/02_style_detection.ipynb#ch0000040vscode-remote?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-KwCzH9GQ-py3.9/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/examen-22-antw/notebooks/../src/training/train_model.py:139\u001b[0m, in \u001b[0;36mtrainloop\u001b[0;34m(epochs, model, optimizer, learning_rate, loss_fn, metrics, train_dataloader, test_dataloader, log_dir, train_steps, eval_steps, patience, factor, tunewriter)\u001b[0m\n\u001b[1;32m    136\u001b[0m     write_gin(log_dir)\n\u001b[1;32m    138\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 139\u001b[0m     train_loss \u001b[39m=\u001b[39m trainbatches(\n\u001b[1;32m    140\u001b[0m         model, train_dataloader, loss_fn, optimizer_, train_steps\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    143\u001b[0m     metric_dict, test_loss \u001b[39m=\u001b[39m evalbatches(\n\u001b[1;32m    144\u001b[0m         model, test_dataloader, loss_fn, metrics, eval_steps\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    147\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n",
      "File \u001b[0;32m~/examen-22-antw/notebooks/../src/training/train_model.py:44\u001b[0m, in \u001b[0;36mtrainbatches\u001b[0;34m(model, traindatastreamer, loss_fn, optimizer, train_steps)\u001b[0m\n\u001b[1;32m     42\u001b[0m yhat \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     43\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(yhat, y)\n\u001b[0;32m---> 44\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     45\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     46\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-KwCzH9GQ-py3.9/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-KwCzH9GQ-py3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "hidden_size_array = (56, 128, 256)\n",
    "dropout_array = (0.1, 0.2, 0.3)\n",
    "\n",
    "result = pd.DataFrame(index = dropout_array, columns=hidden_size_array)\n",
    "print(result)\n",
    "\n",
    "for i in hidden_size_array:\n",
    "    for x in dropout_array:\n",
    "\n",
    "        config = {\n",
    "            \"vocab\": len(v),\n",
    "            \"input_size\": 32,\n",
    "            \"hidden_size\": i,\n",
    "            \"num_layers\": 3,\n",
    "            \"dropout\": x,\n",
    "            \"output_size\": 4,\n",
    "        }\n",
    "\n",
    "        model = rnn.NLPmodel(config)\n",
    "        print(model)\n",
    "\n",
    "        model = train_model.trainloop(\n",
    "            epochs=64,\n",
    "            model=model,\n",
    "            metrics=metrics,\n",
    "            optimizer=torch.optim.Adam,\n",
    "            learning_rate=1e-3,\n",
    "            loss_fn=loss_fn,\n",
    "            train_dataloader=trainstreamer,\n",
    "            test_dataloader=teststreamer,\n",
    "            log_dir=log_dir,\n",
    "            train_steps=25,\n",
    "            eval_steps=25,\n",
    "        )\n",
    "        result.at[x,i] =  model[1]\n",
    "        print(result)\n",
    "\n",
    "\n",
    "        # result[][str(x)] = model[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('exam-22-KwCzH9GQ-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "793d4b0ba659e9ff3f4cb7a1b3752627ccc54f1224ce4526b6cf626154c05563"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
